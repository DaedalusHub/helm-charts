deployment:
  image: 557634078649.dkr.ecr.us-west-2.amazonaws.com/daedalushub/daedalus-ai:latest
  env:
    threads: 14
    contextSize: 512
    modelsPath: "/models"

# Optionally create a PVC, mount the PV to the LocalAI Deployment,
# and download a model to prepopulate the models directory
modelsVolume:
  enabled: true
  url: "https://huggingface.co/eachadea/ggml-vicuna-7b-1.1/resolve/main/ggml-vic7b-q5_0.bin"
  pvc:
    size: 20Gi
    accessModes:
      - ReadWriteOnce
  auth:
    # Optional value for HTTP basic access authentication header
    basic: "" # 'username:password' base64 encoded

modelsTemplate:
  name: "ggml-vic7b-q5_0.bin.tmpl"
  url: "https://github.com/brianhammons/LocalAI/raw/master/prompt-templates/vicuna.tmpl"

service:
  type: LoadBalancer
  annotations:
    external-dns.alpha.kubernetes.io/hostname: models.daedalushub.com
    service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: 1200
